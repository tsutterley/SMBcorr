{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pointCollection as pc\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "%matplotlib notebook\n",
    "from ATL11.RDE import RDE\n",
    "import scipy.interpolate as si\n",
    "import os\n",
    "from ATL11.rtw_mask import rtw_mask_for_delta_time\n",
    "import scipy.ndimage.morphology as morph\n",
    "import netCDF4 as nc\n",
    "\n",
    "data_root='/Volumes/ice2/ben/MAR/ATL11_with_corrections/'\n",
    "PLOT_MAPS=False\n",
    "\n",
    "secular_correction='zsurf_mean'\n",
    "version='v2_zsurf'\n",
    "#secular_correction='smb_mean'\n",
    "#version='v2_SMB'\n",
    "\n",
    "model_list=[ 'MARv3.11.2-ERA-6km','MARv3.11.2-ERA-20km',\n",
    "           'MARv3.11.2-NCEP-20km', 'GSFC-fdm-v1.1']\n",
    "\n",
    "#model_list=[ 'MARv3.11.2-ERA-6km', 'GSFC-fdm-v1.1' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking removed 12.444706506954706% of the ice sheet\n"
     ]
    }
   ],
   "source": [
    "#masks:\n",
    "gimp_mask=pc.grid.data().from_geotif(data_root+'/GimpIceMask_1km.tif')\n",
    "v_mask=pc.grid.data().from_geotif(data_root+'/vel_mask_annual_nmad_lt_20_simplified.tif')\n",
    "v_mask.z=morph.binary_erosion(v_mask.z, structure=np.ones((3,3)))\n",
    "drainage_basins=pc.grid.data().from_geotif(data_root+'/drainage_basins.tif')\n",
    "db_mask=drainage_basins.copy()\n",
    "db_mask.z=np.isfinite(db_mask.z)\n",
    "temp=gimp_mask.interp(db_mask.x, db_mask.y, gridded=True)\n",
    "db_mask.z[np.where(temp<0.5)]=0\n",
    "temp=v_mask.interp(db_mask.x, db_mask.y, gridded=True)\n",
    "db_mask.z[np.where(temp<0.5)]=0\n",
    "\n",
    "temp=np.isfinite(drainage_basins.z).astype(float)-db_mask.z.astype(float)\n",
    "F_eliminated = np.sum(temp!=0)/np.sum(np.isfinite(drainage_basins.z) & (drainage_basins.z>0))\n",
    "\n",
    "print(f\"Masking removed {100*F_eliminated}% of the ice sheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_MAPS:\n",
    "    fig=plt.figure(1); plt.clf()\n",
    "    fig.clf(); hax=[]\n",
    "    hax.append(fig.add_subplot(131))\n",
    "    gimp_mask.show(ax=hax[0])\n",
    "    hax[-1].set_title('ice and rock mask')\n",
    "    hax.append(fig.add_subplot(132, sharex=hax[0], sharey=hax[0]))\n",
    "    drainage_basins.show(ax=hax[1])\n",
    "    hax[-1].set_title('drainage basins')\n",
    "    hax.append(fig.add_subplot(133, sharex=hax[0], sharey=hax[0]))\n",
    "    v_mask.show(ax=hax[2])\n",
    "    hax[-1].set_title('velocity variability < 20 m/yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_MAPS:\n",
    "    fig=plt.figure(2); plt.clf()\n",
    "    fig.clf(); hax=[]\n",
    "    db_mask=drainage_basins.copy()\n",
    "    db_mask.z=np.isfinite(db_mask.z)\n",
    "    temp=gimp_mask.interp(db_mask.x, db_mask.y, gridded=True)\n",
    "    hax.append(fig.add_subplot(131))\n",
    "    plt.imshow(np.isfinite(drainage_basins.z).astype(float) -(temp<0.5).astype(float), origin='lower')\n",
    "    db_mask.z[np.where(temp<0.5)]=0\n",
    "    temp=v_mask.interp(db_mask.x, db_mask.y, gridded=True)\n",
    "    hax.append(fig.add_subplot(132))\n",
    "    plt.imshow(np.isfinite(drainage_basins.z).astype(float) -(temp<0.5).astype(float), origin='lower')\n",
    "    db_mask.z[np.where(temp<0.5)]=0\n",
    "    hax.append(fig.add_subplot(133))\n",
    "    plt.imshow(np.isfinite(drainage_basins.z).astype(float)-db_mask.z.astype(float), origin='lower')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read(fh, group, field):\n",
    "    temp=np.array(fh[group][field])\n",
    "    temp[np.abs(temp) > 1.e15] = np.NaN\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GSFC-fdm-v1.1', 'MARv3.11.2-ERA-10km', 'MARv3.11.2-ERA-20km', 'MARv3.11.2-ERA-6km', 'MARv3.11.2-NCEP-20km', 'RACMO2.3p2-FGRN055', 'along_track_rss', 'atl06_quality_summary', 'cycle_number', 'delta_time', 'dem_h', 'fit_quality', 'h_corr', 'h_corr_sigma', 'h_corr_sigma_systematic', 'latitude', 'longitude', 'quality_summary', 'ref_pt', 'rgt', 'x', 'x_atc', 'y']\n",
      "(11442054, 7, 2)\n",
      "['GSFC-fdm-v1.1', 'MARv3.11.2-ERA-10km', 'MARv3.11.2-ERA-20km', 'MARv3.11.2-ERA-6km', 'MARv3.11.2-NCEP-20km', 'RACMO2.3p2-FGRN055', 'cycle_number', 'delta_time', 'dem_h', 'file_ind', 'fit_quality', 'h_corr', 'h_corr_sigma', 'h_corr_sigma_systematic', 'latitude', 'longitude', 'quality_summary', 'ref_pt', 'x', 'x_atc', 'y']\n",
      "(17260304, 5)\n"
     ]
    }
   ],
   "source": [
    "xo_file=data_root+'/V2/007_crossover_data_v2.h5'\n",
    "#xo_file='/Volumes/ice1/tyler/U07_crossover_data.h5'\n",
    "with h5py.File(xo_file,'r') as h5f:\n",
    "    print(list(h5f.keys()))\n",
    "    print(h5f['x'].shape)\n",
    "\n",
    "xo_cols=7\n",
    "xo_cycles=np.arange(8)\n",
    "#at_file='/Volumes/ice1/tyler/relU07_dump_every_4th.h5'\n",
    "at_file=data_root+'/V2/rel007_dump_every_2nd_v2.h5'\n",
    "with h5py.File(at_file,'r') as h5f:\n",
    "    print(list(h5f.keys()))\n",
    "    print(h5f['x'].shape)\n",
    "\n",
    "at_cols=5\n",
    "at_cycles=np.arange(3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corrections(file, model, D):\n",
    "    if 'GSFC' in model:\n",
    "        GSFC=True\n",
    "        MAR=False\n",
    "    else:\n",
    "        GSFC = False\n",
    "        MAR = True\n",
    "    \n",
    "    with h5py.File(file,'r') as h5f:\n",
    "        print(model)\n",
    "        model_name=model.replace('.','_').replace('-','_')\n",
    "        zsurf_name=model_name+'_zsurf'\n",
    "        D.assign({zsurf_name:safe_read(h5f, model, 'zsurf')})\n",
    "        FAC_name=model_name+'_z_FAC'\n",
    "        if MAR:\n",
    "            D.assign({FAC_name:getattr(D, zsurf_name)-safe_read(h5f, model, 'SMB')/917})\n",
    "        else:            \n",
    "            D.assign({FAC_name:getattr(D, zsurf_name)-safe_read(h5f, model, 'zsmb')})\n",
    "            \n",
    "        if 'zmelt' in h5f[model]:\n",
    "            D.assign({model_name+'_zmelt':safe_read(h5f, model,'zmelt')})\n",
    "        \n",
    "        for field in [ 'smb_mean', 'zsurf_mean']:\n",
    "            if field in h5f[model]:\n",
    "                fieldname=model_name+'_'+field\n",
    "                D.assign({fieldname:safe_read(h5f, model, field)})\n",
    "                print(f\"{fieldname}:{np.mean(np.isfinite(getattr(D, fieldname)), axis=0)}\")\n",
    "                \n",
    "        if 'SMB' in h5f[model]:\n",
    "            # MAR model.  SMB in mmWE\n",
    "            field='SMB'\n",
    "            fieldname=model_name+'_SMB'\n",
    "            D.assign({fieldname:safe_read(h5f, model, 'SMB')/917})\n",
    "            print(f\"{fieldname}:{np.mean(np.isfinite(getattr(D, fieldname)), axis=0)}\")\n",
    "        elif 'zsmb' in h5f[model] and 'GSFC' in model:\n",
    "            fieldname=model_name+'_SMB'\n",
    "            D.assign({fieldname:safe_read(h5f, model, 'zsmb')})\n",
    "            print(f\"{model_name}:\\n{np.mean(np.isfinite(getattr(D, fieldname)), axis=0)}\")\n",
    "        else:\n",
    "            print(f'{model}: no SMB')        \n",
    "        print(\"\\n\\n\")\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_xo=pc.data(columns=xo_cols).from_h5(xo_file, field_dict={None:['along_track_rss', 'atl06_quality_summary', \\\n",
    "            'cycle_number','delta_time', 'h_corr', 'h_corr_sigma','fit_quality', \\\n",
    "            'latitude', 'ref_pt', 'rgt','x','y']})\n",
    "# remove data for which the PS projection gave weird results\n",
    "bad=np.abs(D_xo.x) > 1.e8\n",
    "D_xo.x[bad]=np.NaN\n",
    "D_xo.x=np.nanmax(np.nanmax(D_xo.x, axis=1), axis=1)\n",
    "D_xo.y[bad]=np.NaN\n",
    "D_xo.y=np.nanmax(np.nanmax(D_xo.y, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING xover CORRECTIONS\n",
      "MARv3.11.2-ERA-6km\n",
      "MARv3_11_2_ERA_6km_smb_mean:[[0.         0.20248742]\n",
      " [0.         0.26866767]\n",
      " [0.5642528  0.24577082]\n",
      " [0.31391252 0.18520075]\n",
      " [0.65701857 0.26619215]\n",
      " [0.69672132 0.28270344]\n",
      " [0.58562492 0.22599955]]\n",
      "MARv3_11_2_ERA_6km_zsurf_mean:[[0.         0.20248742]\n",
      " [0.         0.26866767]\n",
      " [0.5642528  0.24577082]\n",
      " [0.31391252 0.18520075]\n",
      " [0.65701857 0.26619215]\n",
      " [0.69672132 0.28270344]\n",
      " [0.58562492 0.22599955]]\n",
      "MARv3_11_2_ERA_6km_SMB:[[0.         0.20248742]\n",
      " [0.         0.26866767]\n",
      " [0.5642528  0.24577082]\n",
      " [0.31391252 0.18520075]\n",
      " [0.65701857 0.26619215]\n",
      " [0.69672132 0.28270344]\n",
      " [0.58562492 0.22599955]]\n",
      "\n",
      "\n",
      "\n",
      "MARv3.11.2-ERA-20km\n",
      "MARv3_11_2_ERA_20km_smb_mean:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "MARv3_11_2_ERA_20km_zsurf_mean:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "MARv3_11_2_ERA_20km_SMB:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "\n",
      "\n",
      "\n",
      "MARv3.11.2-NCEP-20km\n",
      "MARv3_11_2_NCEP_20km_smb_mean:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "MARv3_11_2_NCEP_20km_zsurf_mean:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "MARv3_11_2_NCEP_20km_SMB:[[0.         0.20510269]\n",
      " [0.         0.27106811]\n",
      " [0.5695175  0.24766637]\n",
      " [0.31669235 0.18690281]\n",
      " [0.66321737 0.26833373]\n",
      " [0.70391409 0.28519687]\n",
      " [0.59067367 0.2277883 ]]\n",
      "\n",
      "\n",
      "\n",
      "GSFC-fdm-v1.1\n",
      "GSFC_fdm_v1_1:\n",
      "[[0.         0.23209137]\n",
      " [0.         0.307295  ]\n",
      " [0.63769582 0.27553855]\n",
      " [0.35481147 0.20890559]\n",
      " [0.72878794 0.29635378]\n",
      " [0.0257882  0.01010046]\n",
      " [0.         0.        ]]\n",
      "\n",
      "\n",
      "\n",
      "<class 'pointCollection.data.data'> with shape (11442054, 7, 2),\n",
      "with fields:\n",
      "['along_track_rss', 'atl06_quality_summary', 'cycle_number', 'delta_time', 'h_corr', 'h_corr_sigma', 'fit_quality', 'latitude', 'ref_pt', 'rgt', 'x', 'y', 'MARv3_11_2_ERA_6km_zsurf', 'MARv3_11_2_ERA_6km_z_FAC', 'MARv3_11_2_ERA_6km_zmelt', 'MARv3_11_2_ERA_6km_smb_mean', 'MARv3_11_2_ERA_6km_zsurf_mean', 'MARv3_11_2_ERA_6km_SMB', 'MARv3_11_2_ERA_20km_zsurf', 'MARv3_11_2_ERA_20km_z_FAC', 'MARv3_11_2_ERA_20km_zmelt', 'MARv3_11_2_ERA_20km_smb_mean', 'MARv3_11_2_ERA_20km_zsurf_mean', 'MARv3_11_2_ERA_20km_SMB', 'MARv3_11_2_NCEP_20km_zsurf', 'MARv3_11_2_NCEP_20km_z_FAC', 'MARv3_11_2_NCEP_20km_zmelt', 'MARv3_11_2_NCEP_20km_smb_mean', 'MARv3_11_2_NCEP_20km_zsurf_mean', 'MARv3_11_2_NCEP_20km_SMB', 'GSFC_fdm_v1_1_zsurf', 'GSFC_fdm_v1_1_z_FAC', 'GSFC_fdm_v1_1_SMB']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'along_track_rss': (11442054, 7, 2),\n",
       " 'atl06_quality_summary': (11442054, 7, 2),\n",
       " 'cycle_number': (11442054, 7, 2),\n",
       " 'delta_time': (11442054, 7, 2),\n",
       " 'h_corr': (11442054, 7, 2),\n",
       " 'h_corr_sigma': (11442054, 7, 2),\n",
       " 'fit_quality': (11442054, 7, 2),\n",
       " 'latitude': (11442054, 7, 2),\n",
       " 'ref_pt': (11442054, 7, 2),\n",
       " 'rgt': (11442054, 7, 2),\n",
       " 'x': (11442054,),\n",
       " 'y': (11442054,),\n",
       " 'MARv3_11_2_ERA_6km_zsurf': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_6km_z_FAC': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_6km_zmelt': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_6km_smb_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_6km_zsurf_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_6km_SMB': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_zsurf': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_z_FAC': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_zmelt': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_smb_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_zsurf_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_ERA_20km_SMB': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_zsurf': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_z_FAC': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_zmelt': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_smb_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_zsurf_mean': (11442054, 7, 2),\n",
       " 'MARv3_11_2_NCEP_20km_SMB': (11442054, 7, 2),\n",
       " 'GSFC_fdm_v1_1_zsurf': (11442054, 7, 2),\n",
       " 'GSFC_fdm_v1_1_z_FAC': (11442054, 7, 2),\n",
       " 'GSFC_fdm_v1_1_SMB': (11442054, 7, 2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"READING xover CORRECTIONS\")\n",
    "for model in model_list:\n",
    "    read_corrections(xo_file, model, D_xo)\n",
    "print(D_xo)\n",
    "{field:getattr(D_xo, field).shape for field in D_xo.fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_at=pc.data(columns=at_cols).from_h5(at_file, \\\n",
    "            field_dict={None:['x','y','delta_time','quality_summary','fit_quality','h_corr','h_corr_sigma','dem_h','rgt']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING ALONG-TRACK CORRECTIONS\n",
      "MARv3.11.2-ERA-6km\n",
      "MARv3_11_2_ERA_6km_smb_mean:[0.62599286 0.36150621 0.72378615 0.77438879 0.64255456]\n",
      "MARv3_11_2_ERA_6km_zsurf_mean:[0.62599286 0.36150621 0.72378615 0.77438879 0.64255456]\n",
      "MARv3_11_2_ERA_6km_SMB:[0.62599286 0.36150621 0.72378615 0.77438879 0.64255456]\n",
      "\n",
      "\n",
      "\n",
      "MARv3.11.2-ERA-20km\n",
      "MARv3_11_2_ERA_20km_smb_mean:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "MARv3_11_2_ERA_20km_zsurf_mean:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "MARv3_11_2_ERA_20km_SMB:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "\n",
      "\n",
      "\n",
      "MARv3.11.2-NCEP-20km\n",
      "MARv3_11_2_NCEP_20km_smb_mean:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "MARv3_11_2_NCEP_20km_zsurf_mean:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "MARv3_11_2_NCEP_20km_SMB:[0.63017778 0.36381387 0.72884777 0.78023342 0.64650692]\n",
      "\n",
      "\n",
      "\n",
      "GSFC-fdm-v1.1\n",
      "GSFC_fdm_v1_1:\n",
      "[0.63767869 0.36765129 0.73785444 0.02665411 0.        ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"READING ALONG-TRACK CORRECTIONS\")\n",
    "for model in model_list:\n",
    "    read_corrections(at_file, model, D_at)\n",
    "#print(D_at)\n",
    "#{field:getattr(D_at, field).shape for field in D_at.fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10804827,  6239707, 12492769,  9399834,        0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_at.fields\n",
    "np.sum(np.isfinite(D_at.MARv3_11_2_ERA_6km_zsurf), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (441,)\n",
      "y : (281,)\n",
      "SMB_mean : (281, 441)\n"
     ]
    }
   ],
   "source": [
    "SMB_GSFC=pc.grid.data()\n",
    "with nc.Dataset('/home/ben/git_repos/SMBcorr/gsfc_fdm_v1_gris_SMB_mean_1980_1995.nc','r') as ncf:\n",
    "    for field in ['x','y','SMB_mean']:\n",
    "        SMB_GSFC.assign({field:np.array(ncf[field]).T})\n",
    "        print(f'{field} : {getattr(SMB_GSFC, field).shape}')\n",
    "SMB_GSFC.SMB_mean[SMB_GSFC.SMB_mean==-9999.]=np.NaN\n",
    "# GSFC SMB_mean grid is in m ice /yr. Need to convert to m water /yr.\n",
    "SMB_GSFC.SMB_mean *= .917/365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_xo.index((D_xo.x > drainage_basins.x[0]) & (D_xo.x < drainage_basins.x[-1]) & (D_xo.y > drainage_basins.y[0]) & (D_xo.y < drainage_basins.y[-1]))\n",
    "D_at.index((D_at.x[:,0] > drainage_basins.x[0]) & (D_at.x[:,0] < drainage_basins.x[-1]) & (D_at.y[:,0] > drainage_basins.y[0]) & (D_at.y[:,0] < drainage_basins.y[-1]))\n",
    "\n",
    "dbi=si.RegularGridInterpolator((drainage_basins.y, drainage_basins.x), drainage_basins.z, method='nearest')\n",
    "D_xo.assign({'basin':np.round(dbi.__call__((D_xo.y, D_xo.x))*10)/10})\n",
    "D_at.assign({'basin':np.round(dbi.__call__((D_at.y[:,0], D_at.x[:,0]))*10)/10});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pointCollection.data.data'> with shape (10129933, 7, 2),\n",
       "with fields:\n",
       "['along_track_rss', 'atl06_quality_summary', 'cycle_number', 'delta_time', 'h_corr', 'h_corr_sigma', 'fit_quality', 'latitude', 'ref_pt', 'rgt', 'x', 'y', 'MARv3_11_2_ERA_6km_zsurf', 'MARv3_11_2_ERA_6km_z_FAC', 'MARv3_11_2_ERA_6km_zmelt', 'MARv3_11_2_ERA_6km_smb_mean', 'MARv3_11_2_ERA_6km_zsurf_mean', 'MARv3_11_2_ERA_6km_SMB', 'MARv3_11_2_ERA_20km_zsurf', 'MARv3_11_2_ERA_20km_z_FAC', 'MARv3_11_2_ERA_20km_zmelt', 'MARv3_11_2_ERA_20km_smb_mean', 'MARv3_11_2_ERA_20km_zsurf_mean', 'MARv3_11_2_ERA_20km_SMB', 'MARv3_11_2_NCEP_20km_zsurf', 'MARv3_11_2_NCEP_20km_z_FAC', 'MARv3_11_2_NCEP_20km_zmelt', 'MARv3_11_2_NCEP_20km_smb_mean', 'MARv3_11_2_NCEP_20km_zsurf_mean', 'MARv3_11_2_NCEP_20km_SMB', 'GSFC_fdm_v1_1_zsurf', 'GSFC_fdm_v1_1_z_FAC', 'GSFC_fdm_v1_1_SMB', 'basin', 'ice_mask']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask out non-ice areas\n",
    "D_at.assign({'ice_mask':np.round(gimp_mask.interp(D_at.x[:,0], D_at.y[:,0])*10)/10});\n",
    "D_xo.assign({'ice_mask':np.round(gimp_mask.interp(D_xo.x, D_xo.y)*10)/10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pointCollection.data.data'> with shape (17230774, 5),\n",
       "with fields:\n",
       "['x', 'y', 'delta_time', 'quality_summary', 'fit_quality', 'h_corr', 'h_corr_sigma', 'dem_h', 'rgt', 'MARv3_11_2_ERA_6km_zsurf', 'MARv3_11_2_ERA_6km_z_FAC', 'MARv3_11_2_ERA_6km_zmelt', 'MARv3_11_2_ERA_6km_smb_mean', 'MARv3_11_2_ERA_6km_zsurf_mean', 'MARv3_11_2_ERA_6km_SMB', 'MARv3_11_2_ERA_20km_zsurf', 'MARv3_11_2_ERA_20km_z_FAC', 'MARv3_11_2_ERA_20km_zmelt', 'MARv3_11_2_ERA_20km_smb_mean', 'MARv3_11_2_ERA_20km_zsurf_mean', 'MARv3_11_2_ERA_20km_SMB', 'MARv3_11_2_NCEP_20km_zsurf', 'MARv3_11_2_NCEP_20km_z_FAC', 'MARv3_11_2_NCEP_20km_zmelt', 'MARv3_11_2_NCEP_20km_smb_mean', 'MARv3_11_2_NCEP_20km_zsurf_mean', 'MARv3_11_2_NCEP_20km_SMB', 'GSFC_fdm_v1_1_zsurf', 'GSFC_fdm_v1_1_z_FAC', 'GSFC_fdm_v1_1_SMB', 'basin', 'ice_mask', 'GSFC_fdm_v1_1_smb_mean']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate out the smb_mean field from GSFC FDM (in polar stereographic)\n",
    "\n",
    "D_xo.assign({'GSFC_fdm_v1_1_smb_mean':\\\n",
    "             SMB_GSFC.interp(D_xo.x, D_xo.y, field='SMB_mean')})\n",
    "D_at.assign({'GSFC_fdm_v1_1_smb_mean':\\\n",
    "             SMB_GSFC.interp(D_at.x[:,0], D_at.y[:,0], field='SMB_mean')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask based on the speed variability\n",
    "D_at.assign({'vel_mask':np.round(v_mask.interp(D_at.x[:,0], D_at.y[:,0])*10)/10});\n",
    "D_xo.assign({'vel_mask':np.round(v_mask.interp(D_xo.x, D_xo.y)*10)/10});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering0.4025161725178451\n"
     ]
    }
   ],
   "source": [
    "# filter bad dh values from D_at\n",
    "bad=(np.abs(D_at.h_corr-D_at.dem_h)>100) | np.tile(np.abs(D_at.ice_mask[:, None]-1)>0.01, [1, at_cols]) \n",
    "#bad |= np.tile(np.abs(D_at.vel_mask[:, None]-1)>0.01, [1, at_cols]) \n",
    "bad |= np.tile(~np.isfinite(D_at.basin[:, None]), [1,5])\n",
    "bad |= D_at.fit_quality > 0\n",
    "bad |= rtw_mask_for_delta_time(D_at.delta_time, csv_file='/home/ben/git_repos/ATL11/ICESat-2_TechRefTable_08282020_RTWs.csv')==0\n",
    "print('filtering'+str(np.mean(bad)))\n",
    "D_at.h_corr[bad]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "editing 0.4231075368415566\n"
     ]
    }
   ],
   "source": [
    "# filter bad dh values from D_xo\n",
    "bad= np.tile(np.abs(D_xo.ice_mask[:, None]-1)>0.01, [1, xo_cols]) \n",
    "#bad |= np.tile(np.abs(D_xo.vel_mask[:, None]-1)>0.01, [1, xo_cols]) \n",
    "bad |= np.tile(~np.isfinite(D_xo.basin[:, None]), [1, xo_cols])\n",
    "bad |= np.any(D_xo.atl06_quality_summary==1, axis=2)\n",
    "bad |= np.any(D_xo.fit_quality>0, axis=2)\n",
    "bad |= np.any(rtw_mask_for_delta_time(D_xo.delta_time, csv_file='/home/ben/git_repos/ATL11/ICESat-2_TechRefTable_08282020_RTWs.csv')==0, axis=2)\n",
    "print('editing '+str(np.mean(bad)))\n",
    "temp=D_xo.h_corr.copy()\n",
    "temp[:,:,0][bad]=np.NaN\n",
    "temp[:,:,1][bad]=np.NaN\n",
    "D_xo.h_corr=temp\n",
    "#np.mean(bad[np.isfinite(D_xo.h_corr)])\n",
    "#D_xo.h_corr[bad]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27323549777814776\n"
     ]
    }
   ],
   "source": [
    "# fake the melt for GSFC:\n",
    "D_xo.GSFC_fdm_v1_1_zmelt = D_xo.MARv3_11_2_ERA_6km_zmelt\n",
    "D_at.GSFC_fdm_v1_1_zmelt = D_at.MARv3_11_2_ERA_6km_zmelt\n",
    "print(np.mean(np.isfinite(D_xo.MARv3_11_2_ERA_6km_zmelt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(D, epoch_slices, model, d_delta_t, block_scale, SMB_mean_field):\n",
    "    out={}\n",
    "    for epoch, slices in epoch_slices.items():\n",
    "        s0, s1=slices\n",
    "        dh=pc.data()\n",
    "        dh.assign({'h0':0.5*(D.h_corr[s1]+D.h_corr[s0]),\n",
    "                   'data':(D.h_corr[s1]-D.h_corr[s0]),\n",
    "                   'basin':D.basin.copy()})                          \n",
    "        if len(D.x.shape) > 1:\n",
    "            dh.assign({'x':D.x[:,0].copy(),\\\n",
    "                'y':D.y[:,0].copy()})\n",
    "        else:\n",
    "            dh.assign({'x':D.x.copy(),\\\n",
    "                'y':D.y.copy()})\n",
    "        for in_field, out_field in {'zsurf':'model', 'zmelt':'z_melt', 'z_FAC':'fac', 'SMB':'smb'}.items():\n",
    "            temp=getattr(D, model+'_'+in_field)\n",
    "            dh.assign({out_field:temp[s1]-temp[s0]})\n",
    "        dh.assign({'sigma':np.sqrt(D.h_corr_sigma[s1]**2 +D.h_corr_sigma[s0]**2)})\n",
    "        smb_mean_field=model+'_'+secular_correction\n",
    "        if 'GSFC' not in model:\n",
    "            if smb_mean_field not in D.fields:\n",
    "                #if 'NCEP' in model:\n",
    "                #    smb_mean_field = 'MARv3_11_2_NCEP_20km_zsurf'\n",
    "                #else:\n",
    "                #    smb_mean_field = 'MARv3_11_2_ERA_10km_zsurf'\n",
    "                print(f'MISSING: {smb_mean_field}')\n",
    "            # both SMB and zsurf_mean are in [something]days^-1\n",
    "            dt_data = (D.delta_time[s1]-D.delta_time[s0])/24/3600\n",
    "            if SMB_mean_field == 'smb_mean':\n",
    "                # smb is in MMWE/day -> divide by rho_ice\n",
    "                dh.assign({'mean': dt_data * getattr(D, model+'_'+SMB_mean_field)[s0]/917})\n",
    "            elif SMB_mean_field == 'zsurf_mean':\n",
    "                # ZN6 (zsurf) is in m/day\n",
    "                dh.assign({'mean': dt_data * getattr(D, model+'_'+SMB_mean_field)[s0]})\n",
    "            dh.model -= dh.mean            \n",
    "            dh.smb -= dh.mean\n",
    "\n",
    "            print(f'data valid: {np.mean(np.isfinite(dh.data))}, mean valid: {np.mean(np.isfinite(dh.mean))}')\n",
    "        else:\n",
    "            #GSFC is already corrected (calculate the mean field but don't apply it)\n",
    "            dt_data = (D.delta_time[s1]-D.delta_time[s0])/24/3600\n",
    "            dh.assign({'mean': dt_data * D.GSFC_fdm_v1_1_smb_mean})\n",
    "            #dh.assign({'mean':np.zeros_like(dh.model)})\n",
    "\n",
    "        dh.assign({'corrected': dh.data-dh.model})\n",
    "        dh.assign({'t0':D.delta_time[s0], 't1':D.delta_time[s1], 'vel_mask':D.vel_mask})\n",
    "\n",
    "        good=np.isfinite(dh.corrected)\n",
    "        dh.index(good)\n",
    "\n",
    "        # blockmedian in short-time increments:\n",
    "        t_bin=np.round(dh.t0/d_delta_t)\n",
    "        ut_bin=np.unique(t_bin[np.isfinite(t_bin)])\n",
    "        ii=[]\n",
    "        for ti in ut_bin:\n",
    "            these=np.flatnonzero(t_bin==ti)\n",
    "            bm_ind, count = pc.pt_blockmedian(dh.x[these], dh.y[these], dh.corrected[these], block_scale, index_and_count_only=True)\n",
    "            if np.any(count > 4):\n",
    "                bm_ind=bm_ind[count>4,:]\n",
    "                ii += [np.c_[these[bm_ind[:,0]], these[bm_ind[:,1]]]]\n",
    "        ii=np.concatenate(ii, axis=0)\n",
    "        for field in ['x','y', 'data','model','mean','z_melt','corrected','h0','fac','smb', 'basin', 't0', 't1','vel_mask','sigma']:\n",
    "            temp=getattr(dh, field)\n",
    "            setattr(dh, field, 0.5*(temp[ii[:,0]]+temp[ii[:,1]]))        \n",
    "        out[epoch]=dh\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_delta_t = 10*24*3600\n",
    "block_scale=2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARv3_11_2_ERA_6km\n",
      "data valid: 0.0797581780649487, mean valid: 0.1489683100569372\n",
      "data valid: 0.10449101687049658, mean valid: 0.19538214122442862\n",
      "MARv3_11_2_ERA_20km\n",
      "data valid: 0.0797581780649487, mean valid: 0.15050701717375622\n",
      "data valid: 0.10449101687049658, mean valid: 0.1967484878725259\n",
      "MARv3_11_2_NCEP_20km\n",
      "data valid: 0.0797581780649487, mean valid: 0.15050701717375622\n",
      "data valid: 0.10449101687049658, mean valid: 0.1967484878725259\n",
      "GSFC_fdm_v1_1\n"
     ]
    }
   ],
   "source": [
    "epoch_slices = {'2018.Q4-2019.Q2':[np.s_[:,0,1],\\\n",
    "                                   np.s_[:, 2, 0]],\n",
    "                '2019.Q1-2019.Q2':[np.s_[:,1,1],\\\n",
    "                                   np.s_[:, 2, 0]]}\n",
    "delta_data={}\n",
    "for model in model_list:\n",
    "    model=model.replace('.','_').replace('-','_')\n",
    "    print(model)\n",
    "    delta_data[model]=reduce_data(D_xo, epoch_slices, model, d_delta_t, block_scale, secular_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std of MAR 6km mean field: 0.2275001443283494\n",
      "std of GSFC  mean field: 0.1450124330850931\n",
      "std of MAR 6km smb field: 0.1862717043620675\n",
      "std of GSFC smb field: 0.1364943737635936\n",
      "std of MAR 6km fac field: 0.1702120086906658\n",
      "std of GSFC fac field: 0.1280737508716204\n"
     ]
    }
   ],
   "source": [
    "#CHECK GSFC MEAN FIELD HERE!!!\n",
    "print(f\"std of MAR 6km mean field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km']['2018.Q4-2019.Q2'].mean)}\")\n",
    "print(f\"std of GSFC  mean field: {np.nanstd(delta_data['GSFC_fdm_v1_1']['2018.Q4-2019.Q2'].mean)}\")\n",
    "print(f\"std of MAR 6km smb field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km']['2018.Q4-2019.Q2'].smb)}\")\n",
    "print(f\"std of GSFC smb field: {np.nanstd(delta_data['GSFC_fdm_v1_1']['2018.Q4-2019.Q2'].smb)}\")\n",
    "print(f\"std of MAR 6km fac field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km']['2018.Q4-2019.Q2'].fac)}\")\n",
    "print(f\"std of GSFC fac field: {np.nanstd(delta_data['GSFC_fdm_v1_1']['2018.Q4-2019.Q2'].fac)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARv3_11_2_ERA_6km\n",
      "data valid: 0.15145819914996272, mean valid: 0.23329073899988473\n",
      "data valid: 0.17674284393724854, mean valid: 0.27328366096612955\n",
      "data valid: 0.36986046012790835, mean valid: 0.5807303258692849\n",
      "MARv3_11_2_ERA_20km\n",
      "data valid: 0.15145819914996272, mean valid: 0.2344350288617331\n",
      "data valid: 0.17674284393724854, mean valid: 0.2750302453041285\n",
      "data valid: 0.36986046012790835, mean valid: 0.5850083693280407\n",
      "MARv3_11_2_NCEP_20km\n",
      "data valid: 0.15145819914996272, mean valid: 0.2344350288617331\n",
      "data valid: 0.17674284393724854, mean valid: 0.2750302453041285\n",
      "data valid: 0.36986046012790835, mean valid: 0.5850083693280407\n",
      "GSFC_fdm_v1_1\n"
     ]
    }
   ],
   "source": [
    "epoch_slices = {'2019.Q2-2019.Q3':[np.s_[:,0], np.s_[:,1]], \\\n",
    "                '2019.Q3-2019.Q4':[np.s_[:,1], np.s_[:,2]], \\\n",
    "                '2019.Q4-2020.Q1':[np.s_[:,2], np.s_[:,3]]}\n",
    "for model in model_list:\n",
    "    model=model.replace('.','_').replace('-','_')\n",
    "    print(model)\n",
    "    delta_data[model].update(reduce_data(D_at, epoch_slices, model, d_delta_t, block_scale, secular_correction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK GSFC MEAN FIELD HERE!!!\n",
    "epoch='2019.Q3-2019.Q4'\n",
    "print(f\"std of MAR 6km mean field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km'][epoch].mean)}\")\n",
    "print(f\"std of GSFC  mean field: {np.nanstd(delta_data['GSFC_fdm_v1_1'][epoch].mean)}\")\n",
    "print(f\"std of MAR 6km smb field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km'][epoch].smb)}\")\n",
    "print(f\"std of GSFC smb field: {np.nanstd(delta_data['GSFC_fdm_v1_1'][epoch].smb)}\")\n",
    "print(f\"std of MAR 6km fac field: {np.nanstd(delta_data['MARv3_11_2_ERA_6km'][epoch].fac)}\")\n",
    "print(f\"std of GSFC fac field: {np.nanstd(delta_data['GSFC_fdm_v1_1'][epoch].fac)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the digested data look enough like the raw data\n",
    "\n",
    "this_model=model_list[0].replace('.','_').replace('-','_')\n",
    "fig=plt.figure()\n",
    "fig.add_subplot(121)\n",
    "plt.hist(D_at.h_corr[:,1]-D_at.h_corr[:,0], np.arange(-3, 3, 0.025))\n",
    "plt.title('ATL11')\n",
    "fig.add_subplot(122)\n",
    "plt.hist(delta_data[this_model]['2019.Q2-2019.Q3'].data, np.arange(-3, 3, 0.025))\n",
    "plt.title('reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xover_epochs=['2018.Q4-2019.Q2', '2019.Q1-2019.Q2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the cycle-3 corrections\n",
    "epoch_slices = {'2019.Q2-2019.Q3':[np.s_[:,0], np.s_[:,1]], \\\n",
    "                '2019.Q2-2019.Q4':[np.s_[:,0], np.s_[:,2]], \\\n",
    "                '2019.Q2-2020.Q1':[np.s_[:,0], np.s_[:,3]]}\n",
    "xover_epochs=['2018.Q4-2019.Q2', '2019.Q1-2019.Q2']\n",
    "# these are the same for the crossover cycles\n",
    "delta_data_c3={}\n",
    "for model in delta_data.keys():\n",
    "    delta_data_c3[model]={}\n",
    "    for epoch in xover_epochs:\n",
    "        delta_data_c3[model][epoch] = delta_data[model][epoch].copy()\n",
    "\n",
    "for model in model_list:\n",
    "    model=model.replace('.','_').replace('-','_')\n",
    "    print(model)\n",
    "    delta_data_c3[model].update(reduce_data(D_at, epoch_slices, model, d_delta_t, block_scale, secular_correction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure( figsize=[8, 6])\n",
    "ax=fig.subplots(3, 5, gridspec_kw={'wspace':0.05, 'hspace':0.05})#, sharex=True, sharey=True)\n",
    "strings=xover_epochs+['2019.Q2-2019.Q3', '2019.Q3-2019.Q4', '2019.Q4-2020.Q1']\n",
    "\n",
    "for row, model in enumerate(['Data',  'MARv3_11_2_ERA_6km', 'GSFC_fdm_v1_1']):\n",
    "    for col, epoch in enumerate(strings):\n",
    "        if row==0:\n",
    "            ax[row, col].set_title(epoch.replace('-','\\n to '))\n",
    "        if col==0:\n",
    "            ax[row, col].set_ylabel(model)\n",
    "        if model == 'Data':\n",
    "            D=delta_data['MARv3_11_2_ERA_6km']\n",
    "            temp=D[epoch]\n",
    "            dh=temp.data\n",
    "        else:\n",
    "            D=delta_data[model]\n",
    "            temp=D[epoch]            \n",
    "            dh=D[epoch].corrected   \n",
    "        ind=np.argsort(np.abs(dh))    \n",
    "        hi=ax[row, col].scatter(temp.x[ind], temp.y[ind], 1, c=dh[ind],\\\n",
    "                 vmin=-2.5, vmax=2.5, cmap='Spectral');\n",
    "        ax[row, col].set_xticks([])\n",
    "        ax[row, col].set_yticks([])\n",
    "        plt.axis('equal');\n",
    "plt.colorbar(hi, ax=ax, shrink=0.5, extend='both', label='$\\delta h$, m');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file=data_root+f'/combined_xover_at_differences_{version}.h5'\n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "for model in delta_data.keys():\n",
    "    for epoch in delta_data[model]:\n",
    "        delta_data[model][epoch].to_h5(out_file, group='/'+model+'/'+epoch, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(22, figsize=[8, 6])\n",
    "ax=fig.subplots(3, 5, gridspec_kw={'wspace':0.05, 'hspace':0.05})\n",
    "strings=xover_epochs+['2019.Q2-2019.Q3', '2019.Q2-2019.Q4', '2019.Q2-2020.Q1']\n",
    "\n",
    "for row, model in enumerate(['Data',  'MARv3_11_2_ERA_6km', 'GSFC_fdm_v1_1']):\n",
    "    for col, epoch in enumerate(strings):\n",
    "        if row==0:\n",
    "            ax[row, col].set_title(epoch.replace('-','\\n to '))\n",
    "        if col==0:\n",
    "            ax[row, col].set_ylabel(model.replace('_zsurf','').replace('_6km',''))\n",
    "        if model == 'Data':\n",
    "            D=delta_data_c3['MARv3_11_2_ERA_6km']\n",
    "            temp=D[epoch]\n",
    "            dh=temp.data\n",
    "        else:\n",
    "            D=delta_data_c3[model]\n",
    "            temp=D[epoch]            \n",
    "            dh=D[epoch].corrected     \n",
    "        ind=np.argsort(np.abs(dh))    \n",
    "        hi=ax[row, col].scatter(temp.x[ind], temp.y[ind], 1, c=dh[ind],\\\n",
    "                 vmin=-2.5, vmax=2.5, cmap='Spectral');\n",
    "        ax[row, col].set_xticks([])\n",
    "        ax[row, col].set_yticks([])\n",
    "        plt.axis('equal');\n",
    "plt.colorbar(hi, ax=ax, shrink=0.5, extend='both', label='$\\delta h$, m');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file=data_root+f'/combined_xover_at_differences_wrtc3_{version}.h5'\n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "for model in delta_data_c3.keys():\n",
    "    for epoch in delta_data_c3[model]:\n",
    "        delta_data_c3[model][epoch].to_h5(out_file, group='/'+model+'/'+epoch, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lt /Volumes/ice2/ben/MAR/ATL11_with_corrections//combined_xover_at_differences_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l {out_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure( figsize=[8, 2])\n",
    "ax=fig.subplots(1, 5, gridspec_kw={'wspace':0.05, 'hspace':0.05})#, sharex=True, sharey=True)\n",
    "strings=xover_epochs+['2019.Q2-2019.Q3', '2019.Q3-2019.Q4', '2019.Q4-2020.Q1']\n",
    "\n",
    "\n",
    "for col, epoch in enumerate(strings):\n",
    "    ax[ col].set_title(epoch.replace('-','\\n to '))\n",
    "   \n",
    "    temp=delta_data['MARv3_11_2_ERA_6km'][epoch]\n",
    "    dh=temp.melt\n",
    "        \n",
    "    ind=np.argsort(np.abs(dh))    \n",
    "    hi=ax[col].scatter(temp.x[ind], temp.y[ind], 1, c=dh[ind],\\\n",
    "                 vmin=-2.5, vmax=2.5, cmap='Spectral');\n",
    "    ax[row, col].set_xticks([])\n",
    "    ax[row, col].set_yticks([])\n",
    "    plt.axis('equal');\n",
    "plt.colorbar(hi, ax=ax, shrink=0.5, extend='both', label='$\\delta h$, m');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
